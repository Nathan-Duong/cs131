{"cells":[{"cell_type":"code","execution_count":1,"id":"fce9ce0f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["25/04/29 04:16:25 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n","                                                                                \r"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col\n","\n","# Create a SparkSession instance (an entry point to all Spark functions)\n","spark = SparkSession.builder.appName(\"MYAPP\").getOrCreate()\n","# Read a file in CSV format into Spark DataFrame\n","df = spark.read.csv('gs://dataproc-staging-us-central1-667037614087-6smxgfsy/data/2019-01-h1.csv', header=True, inferSchema=True)"]},{"cell_type":"code","execution_count":2,"id":"c6a0519b","metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n","|vendorid|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|ratecodeid|store_and_fwd_flag|pulocationid|dolocationid|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n","|     1.0| 2019-01-01 00:46:40|  2019-01-01 00:53:20|            1.0|          1.5|       1.0|                 N|       151.0|       239.0|         1.0|        7.0|  0.5|    0.5|      1.65|         0.0|                  0.3|        9.95|                NULL|\n","|     1.0| 2019-01-01 00:59:47|  2019-01-01 01:18:59|            1.0|          2.6|       1.0|                 N|       239.0|       246.0|         1.0|       14.0|  0.5|    0.5|       1.0|         0.0|                  0.3|        16.3|                NULL|\n","|     2.0| 2018-12-21 13:48:30|  2018-12-21 13:52:40|            3.0|          0.0|       1.0|                 N|       236.0|       236.0|         1.0|        4.5|  0.5|    0.5|       0.0|         0.0|                  0.3|         5.8|                NULL|\n","|     2.0| 2018-11-28 15:52:25|  2018-11-28 15:55:45|            5.0|          0.0|       1.0|                 N|       193.0|       193.0|         2.0|        3.5|  0.5|    0.5|       0.0|         0.0|                  0.3|        7.55|                NULL|\n","|     2.0| 2018-11-28 15:56:57|  2018-11-28 15:58:33|            5.0|          0.0|       2.0|                 N|       193.0|       193.0|         2.0|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                NULL|\n","|     2.0| 2018-11-28 16:25:49|  2018-11-28 16:28:26|            5.0|          0.0|       1.0|                 N|       193.0|       193.0|         2.0|        3.5|  0.5|    0.5|       0.0|        5.76|                  0.3|       13.31|                NULL|\n","|     2.0| 2018-11-28 16:29:37|  2018-11-28 16:33:43|            5.0|          0.0|       2.0|                 N|       193.0|       193.0|         2.0|       52.0|  0.0|    0.5|       0.0|         0.0|                  0.3|       55.55|                NULL|\n","|     1.0| 2019-01-01 00:21:28|  2019-01-01 00:28:37|            1.0|          1.3|       1.0|                 N|       163.0|       229.0|         1.0|        6.5|  0.5|    0.5|      1.25|         0.0|                  0.3|        9.05|                NULL|\n","|     1.0| 2019-01-01 00:32:01|  2019-01-01 00:45:39|            1.0|          3.7|       1.0|                 N|       229.0|         7.0|         1.0|       13.5|  0.5|    0.5|       3.7|         0.0|                  0.3|        18.5|                NULL|\n","|     1.0| 2019-01-01 00:57:32|  2019-01-01 01:09:32|            2.0|          2.1|       1.0|                 N|       141.0|       234.0|         1.0|       10.0|  0.5|    0.5|       1.7|         0.0|                  0.3|        13.0|                NULL|\n","+--------+--------------------+---------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+\n","only showing top 10 rows\n","\n"]}],"source":["df.show(10)"]},{"cell_type":"code","execution_count":3,"id":"4359a3c6","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|\n","+---------------+------------+------------+------------+\n","|            1.0|       151.0|       239.0|        9.95|\n","|            1.0|       239.0|       246.0|        16.3|\n","|            3.0|       236.0|       236.0|         5.8|\n","|            5.0|       193.0|       193.0|        7.55|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            5.0|       193.0|       193.0|       13.31|\n","|            5.0|       193.0|       193.0|       55.55|\n","|            1.0|       163.0|       229.0|        9.05|\n","|            1.0|       229.0|         7.0|        18.5|\n","|            2.0|       141.0|       234.0|        13.0|\n","+---------------+------------+------------+------------+\n","only showing top 10 rows\n","\n"]}],"source":["new_dataset = df.select(\"passenger_count\",\"pulocationid\",\"dolocationid\",\"total_amount\")\n","new_dataset.show(10)"]},{"cell_type":"code","execution_count":7,"id":"2f89c231","metadata":{},"outputs":[],"source":["trainDF, testDF = new_dataset.randomSplit([0.8, 0.2])"]},{"cell_type":"code","execution_count":8,"id":"2dd8c4ce","metadata":{},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import DecisionTreeRegressor\n","from pyspark.ml import Pipeline"]},{"cell_type":"code","execution_count":9,"id":"4d78acae","metadata":{},"outputs":[],"source":["assembler = VectorAssembler(\n","    inputCols=[\"passenger_count\", \"pulocationid\", \"dolocationid\"],\n","    outputCol=\"features\"\n",")\n","\n","dt = DecisionTreeRegressor(\n","    featuresCol=\"features\",\n","    labelCol=\"total_amount\"\n",").setMaxBins(32)\n","\n","pipeline = Pipeline(stages=[assembler, dt])"]},{"cell_type":"code","execution_count":10,"id":"600a1895","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["model = pipeline.fit(trainDF)"]},{"cell_type":"code","execution_count":11,"id":"b54fdda7","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 18:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------------+------------+------------+------------+------------------+\n","|passenger_count|pulocationid|dolocationid|total_amount|        prediction|\n","+---------------+------------+------------+------------+------------------+\n","|            0.0|         1.0|         1.0|        90.0|22.152742992951815|\n","|            0.0|         4.0|        79.0|        9.75|12.843170374378925|\n","|            0.0|         4.0|        80.0|       15.95|12.843170374378925|\n","|            0.0|         4.0|       137.0|        9.35|14.284385147633689|\n","|            0.0|         4.0|       170.0|       11.15|14.284385147633689|\n","|            0.0|         7.0|         7.0|         8.8|22.152742992951815|\n","|            0.0|         7.0|        42.0|        29.3|12.843170374378925|\n","|            0.0|         7.0|        48.0|       21.95|12.843170374378925|\n","|            0.0|         7.0|       138.0|        10.8|14.284385147633689|\n","|            0.0|         7.0|       162.0|        13.8|14.284385147633689|\n","|            0.0|         7.0|       229.0|        13.3|14.284385147633689|\n","|            0.0|         7.0|       260.0|        10.8|14.284385147633689|\n","|            0.0|        10.0|       107.0|       63.16|12.843170374378925|\n","|            0.0|        12.0|        45.0|         8.8|12.843170374378925|\n","|            0.0|        12.0|       170.0|        22.3|14.284385147633689|\n","|            0.0|        13.0|        12.0|        6.36|22.152742992951815|\n","|            0.0|        13.0|        13.0|         5.8|22.152742992951815|\n","|            0.0|        13.0|        13.0|         7.3|22.152742992951815|\n","|            0.0|        13.0|        45.0|         9.8|12.843170374378925|\n","|            0.0|        13.0|        88.0|        9.95|12.843170374378925|\n","+---------------+------------+------------+------------+------------------+\n","only showing top 20 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["predictions = model.transform(testDF)\n","\n","predictions.select(\n","    \"passenger_count\",\n","    \"pulocationid\",\n","    \"dolocationid\",\n","    \"total_amount\",\n","    \"prediction\"\n",").show()"]},{"cell_type":"code","execution_count":12,"id":"ef4dc9b9","metadata":{},"outputs":[],"source":["from pyspark.ml.evaluation import RegressionEvaluator"]},{"cell_type":"code","execution_count":13,"id":"b9a190de","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 19:===========================================>              (3 + 1) / 4]\r"]},{"name":"stdout","output_type":"stream","text":["Root Mean Squared Error (RMSE) on test data = 31.287\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["evaluator = RegressionEvaluator(\n","    labelCol=\"total_amount\",\n","    predictionCol=\"prediction\",\n","    metricName=\"rmse\"\n",")\n","\n","rmse = evaluator.evaluate(predictions)\n","print(f\"Root Mean Squared Error (RMSE) on test data = {rmse:.3f}\")"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}